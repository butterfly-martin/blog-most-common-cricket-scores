{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import csv \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import plotly  as py\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import kaleido\n",
    "\n",
    "#Set folder where your code is, and where you have downloaded the raw csvs (see readme)\n",
    "folder = \"C:/Users/user/Documents/GitHub/Martin Shine Blog Posts/\"\n",
    "data = \"C:/Users/user/Documents/GitHub/Martin Shine Blog Posts/raw_csv/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will create a scorecard of each match\n",
    "def extract_scorecard(file_name):\n",
    "    #Make csv into dataframe\n",
    "    balls = pd.read_csv(data + file_name)\n",
    "    #Get just the runs scored by each batsman and then group them by striker to get runs scored by batsman per match\n",
    "    runs = balls[['striker','runs_off_bat','innings']].groupby(['striker','innings']).sum().reset_index().rename(columns = {'striker':'batsman'})\n",
    "\n",
    "    #Did they get out? and if so who and how?\n",
    "    dismissals = balls[['innings','player_dismissed','bowler','wicket_type']][balls.player_dismissed.notnull()]\n",
    "    scorecard = pd.merge(runs, dismissals,how='left',left_on=['batsman','innings'], right_on=['player_dismissed','innings'])\n",
    "    scorecard.drop(columns=['player_dismissed'])\n",
    "\n",
    "    #How many balls did they face?\n",
    "    balls_faced = balls[['striker','runs_off_bat','innings']].groupby(['striker','innings']).count().reset_index().rename(columns = {'runs_off_bat':'balls_faced','striker':'batsman'})\n",
    "    scorecard = pd.merge(scorecard, balls_faced,how='left',on=['batsman','innings'])\n",
    "\n",
    "    #What position did they bat\n",
    "    bat_order = pd.melt(balls[['innings', 'ball','striker', 'non_striker']],id_vars=[\"innings\", \"ball\"]).sort_values(['innings','ball']).reset_index().drop(columns=\"index\")\n",
    "    #This step is needed for the openers, want the person facing the first ball to be batting #1\n",
    "    bat_order.loc[bat_order.variable == 'non_striker', 'ball'] = bat_order['ball']+0.01\n",
    "    #Get lowest ball in an innings that the batsman came in\n",
    "    bat_order  = bat_order.groupby(['value','innings']).min().sort_values(['innings','ball']).reset_index().rename(columns = {'value':'batsman'})\n",
    "    #Assign position\n",
    "    bat_order['position'] = bat_order.groupby('innings').cumcount()+1\n",
    "    scorecard = pd.merge(scorecard, bat_order,how='left',on=['batsman','innings'])\n",
    "\n",
    "    #Get the match info and add that in too\n",
    "    match_info = balls[['match_id','start_date','venue','batting_team','bowling_team']].iloc[0].to_list()\n",
    "    scorecard['match_id']   = match_info[0]\n",
    "    scorecard['start_date'] = match_info[1]\n",
    "    scorecard['match_id'], scorecard['start_date'] , scorecard['venue'] = [match_info[0],match_info[1],match_info[2]]\n",
    "\n",
    "    #Get who batted in what innings\n",
    "    innings = balls.loc[balls.ball == 0.1][['innings','batting_team','bowling_team']]\n",
    "    scorecard = pd.merge(scorecard,innings,how='left',on=['innings'])\n",
    "    #Get columns in nicer order\n",
    "    scorecard = scorecard[['match_id','start_date','venue','batting_team','bowling_team','innings','position','batsman', 'runs_off_bat','balls_faced', 'bowler','wicket_type']].rename(columns = {'runs_off_bat':'runs','wicket_type':'how_out'})\n",
    "    #Sort rows\n",
    "    scorecard = scorecard.sort_values(['innings','position'])\n",
    "    return scorecard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get a list of all files where the csvs are stored (only csv files though!)\n",
    "arr=os.listdir((data))\n",
    "arr = [x for x in arr if \".csv\" in x]\n",
    "#Then import every one and make it one large dataframe\n",
    "for file in arr:\n",
    "    #Might be necessary if one of the imports errors out, uncomment and run again if you need to see which file is causing problems\n",
    "    #print(file)\n",
    "    scorecard = extract_scorecard(file)\n",
    "    if file == arr[0]:\n",
    "        all_scores = scorecard\n",
    "    else:\n",
    "        all_scores = all_scores.append(scorecard)\n",
    "#Write to csv so we can just import that rather than re-do the whole processing if the notebook goes down\n",
    "all_scores.to_csv(folder + \"all_scores.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If necessary, import the csv to get the dataframe, quicker than re-creating the data from all the raw csvs\n",
    "all_scores = pd.read_csv(folder + \"all_scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Best to exclude \"Not outs\", as they're not really scores (switch on or off if change mind)\n",
    "all_scores_excl = all_scores[pd.notnull(all_scores.how_out)]\n",
    "#Create variable which is total innings \n",
    "total_inns = len(all_scores_excl)\n",
    "\n",
    "def get_freq_count(df_in):\n",
    "    #Get a count of each run\n",
    "    df_out = df_in['runs'].value_counts()\n",
    "    #Print no. of innings and sort\n",
    "    print('There are ' + str(len(df_in)) + ' innings in this dataset.')\n",
    "    df_out.sort_index()\n",
    "    return df_out\n",
    "#Set this series to variable run_dist\n",
    "run_dist = get_freq_count(all_scores_excl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Plot all scores\n",
    "df_run_dist = pd.DataFrame({'Runs':run_dist.index, 'Count':run_dist.values})  ## Converting series type to pandas df as plotly accepts dataframe as input. The two columns of df is FuncGroup which is being made by index of series and new variable called count which is made by values of series s.\n",
    "df_run_dist['Percentage'] = (df_run_dist['Count']/total_inns)*100\n",
    "\n",
    "#Make graph\n",
    "data = [go.Bar(\n",
    "x=df_run_dist['Runs'],\n",
    "y=df_run_dist['Percentage'],\n",
    "marker=dict(color='#EAC113')\n",
    ")]\n",
    "layout = go.Layout(plot_bgcolor=\"#383838\",\n",
    "                title='Frequency of each score in International Cricket',\n",
    "                xaxis_title=\"Batsman Score\",\n",
    "                yaxis_title=\"Percentage of All Scores\")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.update_yaxes(range=[0,11.5])\n",
    "fig.update_xaxes(range=[-0.5,100.5])\n",
    "fig.show()\n",
    "fig.write_image(folder + \"graph1.png\",scale=15,engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at 100 mark\n",
    "#Decided, it would be a bit more decipherable if split into 10 run buckets\n",
    "bins = np.arange(0,410,10)\n",
    "\n",
    "#Make labels\n",
    "labels = []\n",
    "for x in range(len(bins)-1):\n",
    "    a = bins[x]\n",
    "    b = bins[x]+9\n",
    "    label = str(a) + \"-\" + str(b)\n",
    "    labels.append(label)\n",
    "    \n",
    "#Cut into 10 run bins\n",
    "df_run_dist['Run_bin'] = pd.cut(df_run_dist['Runs'],bins=bins,right=False,include_lowest=True,labels=labels)\n",
    "df_run_bins = df_run_dist[['Run_bin','Percentage']].groupby(['Run_bin']).sum().reset_index()\n",
    "graph_df = df_run_bins.iloc[6:15]\n",
    "\n",
    "#Make graph\n",
    "data = [go.Bar(\n",
    "x=graph_df['Run_bin'],\n",
    "y=graph_df['Percentage'],\n",
    "marker=dict(color='#EAC113')\n",
    ")]\n",
    "layout = go.Layout(plot_bgcolor=\"#383838\",\n",
    "                title='Frequency of scores around the 100 runs mark',\n",
    "                xaxis_title=\"Batsman Score (Runs in groups of 10)\",\n",
    "                yaxis_title=\"Percentage of All Scores\")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.show()\n",
    "fig.write_image(folder + \"graph2.png\",scale=15,engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Work out batsmans total runs, times out and times not out\n",
    "totals = all_scores[['runs','batsman','batting_team']].groupby(['batsman','batting_team']).sum().reset_index()\n",
    "times_out = all_scores[['how_out','batsman']].groupby(['batsman']).count().reset_index().rename(columns = {'how_out':'n_dismissals'})\n",
    "all_not_outs = all_scores[pd.isnull(all_scores.how_out)]\n",
    "all_not_outs = all_not_outs.assign(how_out=\"not_out\")\n",
    "not_outs =  all_not_outs[['how_out','batsman']].groupby(['batsman']).count().reset_index().rename(columns = {'how_out':'n_not_outs'})\n",
    "\n",
    "#Now merge all tables as one, make NaNs as 0s\n",
    "averages = pd.merge(totals,times_out,how=\"left\",on=[\"batsman\"])\n",
    "averages =pd.merge(averages,not_outs,how=\"left\",on=[\"batsman\"])\n",
    "averages = averages.fillna(0)\n",
    "\n",
    "#Calculate average and number of innings\n",
    "averages['n_inns'] = averages['n_dismissals']+averages['n_not_outs']\n",
    "averages['average'] = averages['runs']/averages['n_dismissals']\n",
    "\n",
    "#If average is inf set it to NaN \n",
    "averages.loc[np.isinf(averages['average']),'average'] = float('NaN')\n",
    "all_not_outs = all_scores[pd.isnull(all_scores.how_out)]\n",
    "\n",
    "#Sort and export as csv\n",
    "averages = averages.sort_values(['average'],ascending=False)\n",
    "averages.to_csv(folder + \"averages.csv\",index=False)\n",
    "averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with all scores\n",
    "combined_scores = pd.merge(all_scores_excl,averages.rename(columns = {'runs':'total_runs'}),how='left',on=['batsman','batting_team'])\n",
    "\n",
    "#Identify \"good\" batsmen, assume bad by default\n",
    "combined_scores['quality'] = 'Bad'\n",
    "combined_scores.loc[(combined_scores['average']>=25) & (combined_scores['total_runs']>= 1000),['quality']] = 'Good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset good and bad scores and make counts\n",
    "good_runs = combined_scores[combined_scores['quality']=='Good']\n",
    "bad_runs = combined_scores[combined_scores['quality']=='Bad']\n",
    "\n",
    "#Use function defined earlier on\n",
    "good_runs_dist = get_freq_count(good_runs)\n",
    "bad_runs_dist = get_freq_count(bad_runs)\n",
    "\n",
    "#Plot all scores\n",
    "def change_to_df(df_in,init_df,quality):\n",
    "    df_out = pd.DataFrame({'Runs':df_in.index, 'Count':df_in.values})  ## Converting series type to pandas df as plotly accepts dataframe as input. The two columns of df is FuncGroup which is being made by index of series and new variable called count which is made by values of series s.\n",
    "    df_out['Percentage'] = (df_out['Count']/len(init_df))*100\n",
    "    df_out['quality'] = quality\n",
    "    df_out = df_out.sort_values(['Runs'])\n",
    "    return df_out\n",
    " \n",
    "#Make into df and append together\n",
    "good_df = change_to_df(good_runs_dist,good_runs,\"Good\")\n",
    "bad_df = change_to_df(bad_runs_dist,bad_runs,\"Bad\")\n",
    "\n",
    "#Make graph\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x=good_df['Runs'],\n",
    "    y=good_df['Percentage'],\n",
    "    mode = 'lines',\n",
    "    name = '\"Good\" Batsmen',\n",
    "    line=dict(color='#EAC113')\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x=bad_df['Runs'],\n",
    "    y=bad_df['Percentage'],\n",
    "    mode = 'lines',\n",
    "    name = '\"Bad\" Batsmen',\n",
    "    line=dict(color='red')\n",
    ")\n",
    "data = [trace0, trace1] # assign traces to data\n",
    "layout = go.Layout(plot_bgcolor=\"#383838\",\n",
    "                title='Comparing score distribution of \"good\" batsmen to \"bad\" batsmen',\n",
    "                xaxis_title=\"Batsman Score\",\n",
    "                yaxis_title=\"Percentage of All Scores\")\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "fig.update_yaxes(range=[0,16.5])\n",
    "fig.update_xaxes(range=[-0.5,50.5])\n",
    "fig.show()\n",
    "fig.write_image(folder + \"graph3.png\",scale=15,engine=\"kaleido\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
